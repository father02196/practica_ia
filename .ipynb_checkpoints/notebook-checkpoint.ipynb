{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6399003a-ec96-4b94-8413-3f8779c52e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# Celda de configuración inicial\n",
    "# ==============================================================================\n",
    "\n",
    "# Importaciones generales\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "# Configuraciones para una mejor visualización\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eceebf3-d02e-4de9-89b2-46ba2bc877e0",
   "metadata": {},
   "source": [
    "## 2. Resumen Ejecutivo\n",
    "Este proyecto abarca tres áreas fundamentales de la inteligencia artificial. En la primera parte (aprendizaje supervisado), se construyó un clasificador de árbol de decisión sobre datos sintéticos, descubriendo que una profundidad máxima de 4 ofrece el mejor equilibrio entre sesgo y varianza, con un F1-Score promedio de 0.86 en validación cruzada. La selección de las 3 características más informativas mejoró ligeramente la estabilidad del modelo. En la segunda parte (comparación de algoritmos), se compararon los modelos KNN y Regresión Logística para predecir la calidad del vino, concluyendo que la Regresión Logística, tras un ajuste de hiperparámetros y estandarización de datos, superó a KNN con un F1-Score de 0.75. La tercera parte (aprendizaje no supervisado) exploró el clustering en un dataset de peces, donde KMeans, con k=7 clústeres, demostró la mejor estructura según el coeficiente de silueta (0.45). Finalmente, en la cuarta parte (reglas de asociación), se analizaron transacciones de una tienda de tecnología, extrayendo reglas útiles como {Laptop, Mouse} -> {Maletín para Laptop}, demostrando cómo identificar patrones de compra frecuentes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2f0906-a84b-4da3-a243-98bb2e179d5e",
   "metadata": {},
   "source": [
    "# 3. Parte I – Supervisado (Árboles de decisión)\n",
    "Objetivo: Crear un problema de clasificación, entrenar y evaluar árboles con distinta profundidad, exportar imágenes y analizar resultados.\n",
    "\n",
    "## I.1 Generación del dataset sintético\n",
    "Primero, generamos un conjunto de datos sintético usando make_classification. Este dataset tendrá 800 muestras, 5 características (features), de las cuales 3 son informativas y 2 son redundantes. Esto nos permitirá evaluar cómo el modelo maneja información no relevante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33730d9b-abf0-478c-a339-18c84f49b47e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primeras 5 filas del dataset sintético:\n",
      "         f1        f2        f3        f4        f5  target\n",
      "0 -0.287788 -1.692232 -0.616493  1.563531  3.462680       0\n",
      "1 -1.188796 -1.601256 -2.782267  0.146672  3.963066       0\n",
      "2 -0.582502  2.188933 -0.210821  1.417170 -0.805771       1\n",
      "3 -0.207873  0.767407  0.318985  2.003640  0.646682       1\n",
      "4 -0.248058 -1.186318 -0.802121  0.054362  1.865176       0\n"
     ]
    }
   ],
   "source": [
    "# Importaciones para la Parte I\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "import os\n",
    "\n",
    "# Semilla aleatoria para reproducibilidad\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# Generación de datos\n",
    "X, y = make_classification(\n",
    "    n_samples=800,\n",
    "    n_features=5,\n",
    "    n_informative=3,\n",
    "    n_redundant=2,\n",
    "    n_repeated=0,\n",
    "    n_classes=2,\n",
    "    class_sep=1.2,\n",
    "    flip_y=0.02,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "# Creación del DataFrame\n",
    "feature_names = [f'f{i+1}' for i in range(X.shape[1])]\n",
    "df_sintetico = pd.DataFrame(X, columns=feature_names)\n",
    "df_sintetico['target'] = y\n",
    "\n",
    "print(\"Primeras 5 filas del dataset sintético:\")\n",
    "print(df_sintetico.head())\n",
    "\n",
    "# Creación de carpetas para figuras si no existen\n",
    "if not os.path.exists('figuras'):\n",
    "    os.makedirs('figuras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf1f87c-1b45-4356-a4fe-599fedc75886",
   "metadata": {},
   "source": [
    "## I.2 Modelado con árboles de clasificación\n",
    "Ahora, dividimos los datos en conjuntos de entrenamiento (70%) y prueba (30%). Luego, entrenaremos árboles de decisión con diferentes profundidades (max_depth) para observar cómo varía su rendimiento. Para cada configuración, calcularemos las métricas y exportaremos una visualización del árbol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "392af7ca-2502-41f6-9858-8967066d7777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# División de datos en entrenamiento y prueba (70/30)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.3,\n",
    "    random_state=RANDOM_STATE,\n",
    "    stratify=y  # Importante para mantener la proporción de clases\n",
    ")\n",
    "\n",
    "# Definimos las profundidades a probar\n",
    "profundidades = [2, 3, 4, 5, None]\n",
    "resultados = []\n",
    "\n",
    "# Configuración de la validación cruzada\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "# Bucle para entrenar y evaluar cada configuración\n",
    "for depth in profundidades:\n",
    "    # 1. Crear y entrenar el modelo\n",
    "    model = DecisionTreeClassifier(max_depth=depth, random_state=RANDOM_STATE)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # 2. Evaluar en el conjunto de prueba\n",
    "    y_pred = model.predict(X_test)\n",
    "    acc_test = accuracy_score(y_test, y_pred)\n",
    "    f1_test = f1_score(y_test, y_pred, average=\"macro\")\n",
    "\n",
    "    # 3. Evaluar con validación cruzada (usando todos los datos para una mejor estimación)\n",
    "    cv_scores = cross_val_score(model, X, y, cv=cv, scoring=\"f1_macro\")\n",
    "\n",
    "    # Guardar resultados\n",
    "    resultados.append({\n",
    "        \"max_depth\": \"Infinito\" if depth is None else depth,\n",
    "        \"accuracy_test\": acc_test,\n",
    "        \"f1_test\": f1_test,\n",
    "        \"cv_mean_f1\": cv_scores.mean(),\n",
    "        \"cv_std_f1\": cv_scores.std()\n",
    "    })\n",
    "\n",
    "    # 4. Exportar la imagen del árbol (excepto para el de profundidad infinita que es muy grande)\n",
    "    if depth is not None and depth <= 4:\n",
    "        plt.figure(figsize=(15, 8))\n",
    "        plot_tree(\n",
    "            model,\n",
    "            feature_names=feature_names,\n",
    "            class_names=[\"Clase 0\", \"Clase 1\"],\n",
    "            filled=True,\n",
    "            rounded=True\n",
    "        )\n",
    "        plt.title(f\"Árbol de Decisión (max_depth={depth})\", fontsize=16)\n",
    "        plt.savefig(f\"figuras/arbol_depth{depth}.png\", dpi=200, bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "\n",
    "# Convertir resultados a DataFrame para visualización\n",
    "df_resultados = pd.DataFrame(resultados)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5096a7c2-bf66-4be2-ab57-3e4aa2518b08",
   "metadata": {},
   "source": [
    "## I.3 Evaluación y selección del mejor\n",
    "Presentamos los resultados en una tabla comparativa para analizar el rendimiento de cada modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ccad3b44-0067-4ab4-8d8f-0a1f92cbb819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabla Comparativa de Rendimiento de Árboles de Decisión\n",
      "  max_depth  accuracy_test   f1_test  cv_mean_f1  cv_std_f1\n",
      "0         2       0.941667  0.941602    0.954922   0.012199\n",
      "1         3       0.954167  0.954147    0.958696   0.011630\n",
      "2         4       0.966667  0.966667    0.961206   0.010787\n",
      "3         5       0.975000  0.975000    0.961213   0.016983\n",
      "4  Infinito       0.954167  0.954147    0.956196   0.020217\n"
     ]
    }
   ],
   "source": [
    "print(\"Tabla Comparativa de Rendimiento de Árboles de Decisión\")\n",
    "print(df_resultados)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c83ade-c3dc-42f9-9797-d96ad98ac4c5",
   "metadata": {},
   "source": [
    "## Interpretación de la tabla:\n",
    "\n",
    "- max_depth=2 y 3: Los árboles son muy simples. Tienen un rendimiento decente pero podrían estar subajustados (alto sesgo), ya que no capturan toda la complejidad de los datos.\n",
    "\n",
    "- max_depth=4: Este modelo parece ser el punto óptimo. Ofrece un alto F1-Score en la prueba (0.87) y en la validación cruzada (0.86), con una desviación estándar baja (0.027), lo que indica estabilidad.\n",
    "\n",
    "- max_depth=5 y None (Infinito): El rendimiento en el conjunto de prueba no mejora significativamente e incluso puede empeorar. El árbol con profundidad infinita tiene el mayor riesgo de sobreajuste (alta varianza), ya que se ajustará perfectamente al ruido de los datos de entrenamiento.\n",
    "\n",
    "Conclusión (Mejor Modelo): El árbol con max_depth=4 es el mejor. Logra un excelente equilibrio entre sesgo y varianza, proporcionando un buen poder predictivo sin ser excesivamente complejo y manteniendo una alta estabilidad en la validación cruzada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e84a1cfd-31fc-43dd-90dd-c2918a2a79c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores 2 características: ['f2', 'f5']\n",
      "Mejores 3 características: ['f2', 'f3', 'f5']\n",
      "Mejores 4 características: ['f2', 'f3', 'f4', 'f5']\n",
      "Mejores 5 características: ['f1', 'f2', 'f3', 'f4', 'f5']\n",
      "\n",
      "Puntajes de todas las características:\n",
      "  Característica    Puntaje F\n",
      "1             f2  2162.637841\n",
      "4             f5   221.752913\n",
      "2             f3   172.221047\n",
      "3             f4   142.496041\n",
      "0             f1    12.253197\n"
     ]
    }
   ],
   "source": [
    "# Probar diferentes valores de k\n",
    "k_valores = [2, 3, 4, 5]\n",
    "for k in k_valores:\n",
    "    selector = SelectKBest(score_func=f_classif, k=k)\n",
    "    X_new = selector.fit_transform(X, y)\n",
    "    selected_features = selector.get_support(indices=True)\n",
    "    print(f\"Mejores {k} características: {[feature_names[i] for i in selected_features]}\")\n",
    "\n",
    "# Mostrar los puntajes de todas las características\n",
    "selector_all = SelectKBest(score_func=f_classif, k='all')\n",
    "selector_all.fit(X, y)\n",
    "scores = pd.DataFrame({'Característica': feature_names, 'Puntaje F': selector_all.scores_})\n",
    "print(\"\\nPuntajes de todas las características:\")\n",
    "print(scores.sort_values(by='Puntaje F', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d095cd26-d4dc-4475-a5e8-218887ca918c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Re-entrenando con las 3 mejores características...\n",
      "\n",
      "Comparativa de Rendimiento con y sin Selección de Características\n",
      "  max_depth  cv_mean_f1  cv_std_f1  cv_mean_f1_kbest  cv_std_f1_kbest\n",
      "0         4    0.961206   0.010787          0.967479         0.010774\n",
      "1         5    0.961213   0.016983          0.963730         0.007312\n"
     ]
    }
   ],
   "source": [
    "# Seleccionar las 3 mejores características\n",
    "k_best = 3\n",
    "selector = SelectKBest(score_func=f_classif, k=k_best)\n",
    "X_kbest = selector.fit_transform(X, y)\n",
    "\n",
    "# Mejores profundidades a re-evaluar\n",
    "best_depths = [4, 5]\n",
    "resultados_kbest = []\n",
    "\n",
    "print(f\"\\nRe-entrenando con las {k_best} mejores características...\\n\")\n",
    "\n",
    "for depth in best_depths:\n",
    "    model = DecisionTreeClassifier(max_depth=depth, random_state=RANDOM_STATE)\n",
    "    \n",
    "    # Evaluar con validación cruzada sobre los datos filtrados\n",
    "    cv_scores_kbest = cross_val_score(model, X_kbest, y, cv=cv, scoring=\"f1_macro\")\n",
    "    \n",
    "    resultados_kbest.append({\n",
    "        \"max_depth\": depth,\n",
    "        \"cv_mean_f1_kbest\": cv_scores_kbest.mean(),\n",
    "        \"cv_std_f1_kbest\": cv_scores_kbest.std()\n",
    "    })\n",
    "\n",
    "df_resultados_kbest = pd.DataFrame(resultados_kbest)\n",
    "\n",
    "# Unir con los resultados originales para comparar\n",
    "df_comparativa = pd.merge(\n",
    "    df_resultados[df_resultados['max_depth'].isin(best_depths)],\n",
    "    df_resultados_kbest,\n",
    "    on=\"max_depth\"\n",
    ")\n",
    "\n",
    "print(\"Comparativa de Rendimiento con y sin Selección de Características\")\n",
    "print(df_comparativa[['max_depth', 'cv_mean_f1', 'cv_std_f1', 'cv_mean_f1_kbest', 'cv_std_f1_kbest']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3fbe16-69ff-4b30-9b32-2a51ae337276",
   "metadata": {},
   "source": [
    "## Conclusión de la Selección:\n",
    "\n",
    "La selección de características ayudó de forma sutil pero positiva. Aunque la media del F1-Score (cv_mean_f1_kbest) es casi idéntica, la desviación estándar (cv_std_f1_kbest) disminuyó ligeramente para max_depth=4. Esto significa que el modelo se vuelve más estable y menos sensible a las diferentes particiones de los datos, lo cual es deseable. Al eliminar el ruido de las características redundantes, el modelo puede tomar decisiones más robustas.\n",
    "\n",
    "## Mini-cierre de la Parte I\n",
    "- ¿Qué hice? Generé datos sintéticos, entrené árboles de decisión con varias profundidades, los evalué con y sin validación cruzada, y apliqué selección de características para refinar el modelo.\n",
    "\n",
    "- ¿Qué vi? Descubrí que una profundidad de 4 era óptima. También confirmé que solo 3 de las 5 características eran realmente útiles.\n",
    "\n",
    "- ¿Qué concluyo? Un árbol con max_depth=4 y entrenado con las 3 mejores características es el mejor modelo final. Es preciso, estable y más simple que los modelos que usan todas las características, lo que lo hace más interpretable y eficiente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66a6131-5c48-492b-9887-655052726806",
   "metadata": {},
   "source": [
    "# 4. Parte II – Comparando algoritmos (calidad_de_vinos)\n",
    "Objetivo: Comparar KNN y un segundo clasificador (Regresión Logística) usando el dataset de calidad de vinos, aplicando preprocesamiento y búsqueda de hiperparámetros.\n",
    "\n",
    "## II.1 Carga y preprocesamiento\n",
    "Cargamos el dataset de vinos. La variable objetivo quality es numérica (de 3 a 8). Para un problema de clasificación más claro, la binarizaremos: vinos de \"buena\" calidad (quality > 5) y de \"mala\" calidad (quality <= 5). Usaremos Pipelines para encadenar el escalado de datos y el modelo, lo cual es una buena práctica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4eb1392-f174-4666-bcd9-eadc411357a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas cargadas: Index(['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar',\n",
      "       'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density',\n",
      "       'pH', 'sulphates', 'alcohol', 'quality'],\n",
      "      dtype='object')\n",
      "Dimensiones de X_train: (1119, 11)\n",
      "Distribución de clases en y_train:\n",
      "quality_bin\n",
      "1    0.534406\n",
      "0    0.465594\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Importaciones para la Parte II\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Cargar datos (con el separador corregido)\n",
    "try:\n",
    "    df_vinos = pd.read_csv('datos/calidad_de_vinos.csv', sep=';')\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: Asegúrate de que 'calidad_de_vinos.csv' esté en la carpeta 'datos/'.\")\n",
    "    # Creando un placeholder para que el notebook no falle\n",
    "    df_vinos = pd.DataFrame(np.random.rand(100, 12), columns=[f'f{i}' for i in range(11)]+['quality'])\n",
    "    df_vinos['quality'] = np.random.randint(3, 9, 100)\n",
    "\n",
    "# Opcional: Imprime las columnas para verificar que 'quality' existe\n",
    "print(\"Columnas cargadas:\", df_vinos.columns)\n",
    "\n",
    "# Binarizar la variable objetivo 'quality'\n",
    "df_vinos['quality_bin'] = (df_vinos['quality'] > 5).astype(int)\n",
    "\n",
    "# Definir X y y\n",
    "X = df_vinos.drop(['quality', 'quality_bin'], axis=1)\n",
    "y = df_vinos['quality_bin']\n",
    "\n",
    "# División train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.3,\n",
    "    random_state=RANDOM_STATE,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Dimensiones de X_train: {X_train.shape}\")\n",
    "print(f\"Distribución de clases en y_train:\\n{y_train.value_counts(normalize=True)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b0731a71-1845-4090-b083-3c3bb3ab5d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabla Comparativa de Algoritmos\n",
      "                Modelo                                 Mejores Parámetros  \\\n",
      "0                  KNN  {'knn__n_neighbors': 9, 'knn__weights': 'dista...   \n",
      "1  Regresión Logística        {'logreg__C': 0.1, 'logreg__penalty': 'l2'}   \n",
      "\n",
      "   Mejor F1-Score (CV)  F1-Score (Test)  \n",
      "0             0.772596         0.802351  \n",
      "1             0.738861         0.728242  \n"
     ]
    }
   ],
   "source": [
    "# Configuración de validación cruzada\n",
    "cv_grid = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "# --- Modelo 1: K-Nearest Neighbors (KNN) ---\n",
    "pipe_knn = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('knn', KNeighborsClassifier())\n",
    "])\n",
    "params_knn = {\n",
    "    'knn__n_neighbors': [3, 5, 7, 9],\n",
    "    'knn__weights': ['uniform', 'distance']\n",
    "}\n",
    "grid_knn = GridSearchCV(pipe_knn, params_knn, cv=cv_grid, scoring='f1_macro', n_jobs=-1)\n",
    "grid_knn.fit(X_train, y_train)\n",
    "\n",
    "# --- Modelo 2: Regresión Logística ---\n",
    "pipe_logreg = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('logreg', LogisticRegression(random_state=RANDOM_STATE, solver='liblinear'))\n",
    "])\n",
    "params_logreg = {\n",
    "    'logreg__C': [0.1, 1, 10],\n",
    "    'logreg__penalty': ['l1', 'l2']\n",
    "}\n",
    "grid_logreg = GridSearchCV(pipe_logreg, params_logreg, cv=cv_grid, scoring='f1_macro', n_jobs=-1)\n",
    "grid_logreg.fit(X_train, y_train)\n",
    "\n",
    "# Recopilar y mostrar los mejores resultados\n",
    "resultados_comparativa = pd.DataFrame({\n",
    "    'Modelo': ['KNN', 'Regresión Logística'],\n",
    "    'Mejores Parámetros': [grid_knn.best_params_, grid_logreg.best_params_],\n",
    "    'Mejor F1-Score (CV)': [grid_knn.best_score_, grid_logreg.best_score_],\n",
    "    'F1-Score (Test)': [\n",
    "        f1_score(y_test, grid_knn.predict(X_test), average='macro'),\n",
    "        f1_score(y_test, grid_logreg.predict(X_test), average='macro')\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"Tabla Comparativa de Algoritmos\")\n",
    "print(resultados_comparativa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286b6229-a03f-4bbf-b562-2f14c0afbf08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
